{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import nodegam\n",
    "from feature_utils import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'format':'OD',\n",
    "    'anneal_steps' : 5000,\n",
    "    'quantile_noise':1e-4,\n",
    "    'n_quantiles':3000,\n",
    "    'min_temp':0.1,\n",
    "    'num_trees':300,\n",
    "    'num_layers':8,\n",
    "    'depth':6,\n",
    "    'lr':1e-4,\n",
    "    'lr_warmup_steps':1000,\n",
    "    'batch_size':128,\n",
    "    'lr_decay_steps' : 5000,\n",
    "    'early_stopping_rounds' : 1000,\n",
    "    'output_dropout':0.2,\n",
    "    'last_dropout':0.3,\n",
    "    'colsample_bytree':0.5,\n",
    "    'selectors_detach':0,\n",
    "    'ga2m':1,\n",
    "    'l2_lambda':0.3,\n",
    "    'nus_min':0.7,\n",
    "    'nus_max':1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use GPU 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "name = 'OD_ga2m_2024.12.04_07:45'\n",
    "# Create directory\n",
    "os.makedirs(pjoin('logs', name), exist_ok=True)\n",
    "\n",
    "csv_path = \"./logs/parameters.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    parameters_df = pd.read_csv(csv_path)\n",
    "    columns_to_check = [col for col in parameters_df.columns if col in parameters]\n",
    "    matching_rows = parameters_df[columns_to_check].eq(pd.Series(parameters)).all(axis=1)\n",
    "    if matching_rows.any():\n",
    "        print(f\"Already trained a model on this parameter with name : {parameters_df['name']} and test_error : {parameters_df['test_error']}\")\n",
    "        exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Normalize y. mean = 42.95601381439407, std = 40.35418349568578\n"
     ]
    }
   ],
   "source": [
    "nodegam.utils.seed_everything(seed=83)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "format = \"OD\"\n",
    "train_data_path = os.path.join(\"..\", \"data\", \"processed\", \"train\", f\"15_{format}.csv\")\n",
    "test_data_path = os.path.join(\"..\", \"data\", \"processed\", \"test\", f\"15_{format}.csv\")\n",
    "\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "\n",
    "y_train = train_df[\"fantasy_points\"].values.squeeze()\n",
    "y_test_id = test_df[\"match_id\"]\n",
    "y_test = test_df[\"fantasy_points\"].values.squeeze()\n",
    "\n",
    "\n",
    "X_train = process(train_df, 15, False)\n",
    "X_test = process(test_df, 15, False)\n",
    "\n",
    "data = {\n",
    "    'X_train' : X_train,\n",
    "    'y_train' : y_train,\n",
    "    'X_test' : X_test,\n",
    "    'y_test' : y_test,\n",
    "    'problem' : \"regression\"\n",
    "}\n",
    "\n",
    "preprocessor = nodegam.mypreprocessor.MyPreprocessor(\n",
    "    cat_features=data.get('cat_features', None),\n",
    "    y_normalize=(data['problem'] == 'regression'), # Normalize target y to mean 0 and 1 in regression\n",
    "    random_state=1337, quantile_transform=True,\n",
    "    quantile_noise=data.get('quantile_noise', parameters['quantile_noise']),\n",
    "    n_quantiles=parameters['n_quantiles'],\n",
    ")\n",
    "\n",
    "X_train, y_train = data['X_train'], data['y_train']\n",
    "X_test, y_test = data['X_test'], data['y_test']\n",
    "preprocessor.fit(X_train, y_train)\n",
    "\n",
    "X_train, y_train = preprocessor.transform(X_train, y_train)\n",
    "X_test, y_test = preprocessor.transform(X_test, y_test)\n",
    "\n",
    "anneal_steps = parameters['anneal_steps']\n",
    "\n",
    "choice_fn = nodegam.nn_utils.EM15Temp(max_temp=1., min_temp=parameters['min_temp'], steps=anneal_steps)\n",
    "\n",
    "# Temperature annealing for entmoid\n",
    "model = nodegam.arch.GAMBlock(\n",
    "    in_features=X_train.shape[1],\n",
    "    num_trees=parameters['num_trees'],\n",
    "    num_layers=parameters['num_layers'],\n",
    "    num_classes=1,\n",
    "    addi_tree_dim=1,\n",
    "    depth=parameters['depth'],\n",
    "    choice_function=choice_fn,\n",
    "    bin_function=nodegam.nn_utils.entmoid15,\n",
    "    output_dropout=parameters['output_dropout'],\n",
    "    last_dropout=parameters['last_dropout'],\n",
    "    colsample_bytree=parameters['colsample_bytree'],\n",
    "    selectors_detach=parameters['selectors_detach'], # This is only used to save memory in large datasets like epsilon\n",
    "    add_last_linear=True,\n",
    "    ga2m=parameters['ga2m'],\n",
    "    l2_lambda=parameters['l2_lambda'],\n",
    ").to(device)\n",
    "\n",
    "step_callbacks = [choice_fn.temp_step_callback]\n",
    "\n",
    "from qhoptim.pyt import QHAdam\n",
    "optimizer_params = {'nus': (parameters['nus_min'], parameters['nus_max']), 'betas': (0.95, 0.998)}\n",
    "\n",
    "trainer = nodegam.trainer.Trainer(\n",
    "    model=model,\n",
    "    experiment_name=name,\n",
    "    warm_start=True, # if True, will load latest checkpt in the saved dir logs/${name}\n",
    "    Optimizer=QHAdam,\n",
    "    optimizer_params=optimizer_params,\n",
    "    lr=parameters['lr'],\n",
    "    lr_warmup_steps=parameters['lr_warmup_steps'],\n",
    "    verbose=False,\n",
    "    n_last_checkpoints=5,\n",
    "    step_callbacks=step_callbacks, # Temp annelaing\n",
    "    fp16=1,\n",
    "    problem=data['problem'],\n",
    ")\n",
    "batch_size = parameters['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai21btech11025/conda/envs/dream11/lib/python3.9/site-packages/nodegam/trainer.py:131: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error rate: 1.0612823963165283\n"
     ]
    }
   ],
   "source": [
    "trainer.load_checkpoint(tag='best')\n",
    "test_err = trainer.evaluate_mse(X_test, y_test, device=device, batch_size=2 * batch_size)\n",
    "\n",
    "print(\"Test Error rate: {}\".format(test_err))\n",
    "\n",
    "# Clean up\n",
    "trainer.remove_old_temp_checkpoints(number_ckpts_to_keep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nodegam.utils import get_latest_file, check_numpy, process_in_chunks\n",
    "\n",
    "X_test = torch.as_tensor(X_test, device=device)\n",
    "y_test = check_numpy(y_test)\n",
    "model.train(False)\n",
    "with torch.no_grad():\n",
    "    prediction = process_in_chunks(model, X_test, batch_size=batch_size)\n",
    "    prediction = check_numpy(prediction)\n",
    "\n",
    "mu = 42.95601381439407\n",
    "sigma = 40.35418349568578\n",
    "\n",
    "original_data_test = [mu + z * sigma for z in prediction]\n",
    "original_data_true = [mu + z * sigma for z in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_matching_indices :  6.350961538461538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.350961538461538"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from feature_utils import compute_overlap_true_test\n",
    "\n",
    "compute_overlap_true_test(original_data_true, original_data_test, y_test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "gam_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor with main features: torch.Size([22, 35, 1])\n",
      "Abdul Razzaq's selection is due to his recent impressive run-outs and consistent bowling figures in the last 15 matches, coupled with a good venue average for wickets.  His overall bowling performance significantly contributed to his high predicted score.\n",
      "\n",
      "\n",
      "A Kumble's selection is justified by his strong performance at the venue (high wicket average), combined with decent bowling stats in recent matches. His experience and ability to contain runs also played a role.\n",
      "\n",
      "\n",
      "Arshad Khan made the team based on his strong bowling performance at the venue and his consistent dot ball bowling in recent matches. His experience also contributed to his selection.\n",
      "\n",
      "\n",
      "D Mongia's high predicted score stems from his excellent dot ball bowling record in recent matches and his performance at the venue. His consistent batting in the last 15 games also added to his fantasy score.\n",
      "\n",
      "\n",
      "Harbhajan Singh's selection is attributed to his bowling performance at this venue, his high number of balls bowled, and runs conceded in recent matches.  His overall experience in the match type also contributes.\n",
      "\n",
      "\n",
      "Iftikhar Anjum's inclusion is due to his bowling performance at the venue and his bowling statistics in recent matches which includes a high number of balls bowled and runs conceded.  His overall experience in the match type also contributes.\n",
      "\n",
      "\n",
      "Inzamam-ul-Haq's selection is based on his consistent performance at the venue and his overall experience in similar match types. His recent economy rate also played a role.\n",
      "\n",
      "\n",
      "Kamran Akmal's high projected score is largely due to his bowling performance at the specific venue and his good recent performances. His ability to contain runs and overall experience in the match type also helped.\n",
      "\n",
      "\n",
      "L Balaji's selection is mainly due to his bowling performance at the venue, along with consistent run-outs and dot balls bowled in his recent matches.\n",
      "\n",
      "\n",
      "M Kaif's selection is primarily based on his performance at the venue, and his consistent bowling statistics, including the number of balls bowled and runs conceded, in his last 15 matches. His overall experience in the match type also contributes.\n",
      "\n",
      "\n",
      "Mohammad Yousuf's high fantasy score prediction is explained by his performance at the venue combined with his recent bowling stats. The number of balls bowled and runs conceded in his recent matches played a significant role.\n",
      "\n",
      "\n",
      "MS Dhoni's exclusion despite a good bowling performance at the venue and overall bowling statistics is due to stiff competition within the squad for similar roles.\n",
      "\n",
      "\n",
      "\n",
      "Naved-ul-Hasan, despite good bowling figures at the venue and overall decent bowling stats, wasn't selected due to stronger competition from other players in similar roles.\n",
      "\n",
      "\n",
      "R Dravid's omission, despite some good past performance, reflects tough competition; his recent bowling and overall performance were not considered superior to the selected players.\n",
      "\n",
      "\n",
      "Salman Butt's exclusion, despite a respectable bowling performance at the venue and overall bowling statistics, resulted from a stronger overall performance from the selected players.\n",
      "\n",
      "\n",
      "Shahid Afridi's exclusion, despite showing promise in bowling at the venue and overall statistics, was due to higher-performing players in the selected team.\n",
      "\n",
      "\n",
      "Shoaib Malik's non-selection is a result of strong competition, despite his decent overall and recent bowling figures at the venue and overall matches played.\n",
      "\n",
      "\n",
      "SR Tendulkar's omission, although he had a good overall bowling performance at the venue and overall match type, highlights the strong competition from other players selected.\n",
      "\n",
      "\n",
      "V Sehwag's exclusion, despite his good run-out stats and overall performance, is explained by stronger competition from other players offering better value to the fantasy team.\n",
      "\n",
      "\n",
      "Younis Khan's non-selection, even with his decent bowling performance at the venue and overall bowling statistics, is due to a higher level of performance and strong competition from other players selected.\n",
      "\n",
      "\n",
      "\n",
      "Yuvraj Singh's non-selection, although he showed a good bowling performance at the venue and overall bowling statistics, is due to higher performing players selected for the team.\n",
      "\n",
      "\n",
      "Z Khan's non-selection, despite showing a decent bowling performance at the venue, and overall bowling statistics, is a consequence of the stronger performance of the selected players for the team.\n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'output' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 157\u001b[0m\n\u001b[1;32m    151\u001b[0m     explaination_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [debut_explaination] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(debut_ids)\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, explaination_list\n\u001b[0;32m--> 157\u001b[0m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1451893\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 150\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(date, format, players_id_list, match_id)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# for explanation in explaination_list: print(explanation)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# explaination_list = explain_outputs(model[format], test_data, columns, non_debut_names)\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# backup_explaination = backup_outputs(model[format], test_data, columns, non_debut_names)\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m \u001b[38;5;241m+\u001b[39m [debut_player_points] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(debut_ids)\n\u001b[1;32m    151\u001b[0m explaination_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [debut_explaination] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(debut_ids)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, explaination_list\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'output' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from explainability import *\n",
    "# from model_utils import MLPModel\n",
    "from feature_utils import process\n",
    "from nodegam.utils import process_in_chunks, check_numpy\n",
    "\n",
    "\n",
    "test_df = {}\n",
    "test_df_after_10nov = {}\n",
    "model = {}\n",
    "k = 15\n",
    "for format in [\"OD\"]:#, \"T20\", \"Test\"]:\n",
    "    test_df[format] = pd.read_csv(f\"../data/processed/test/{k}_{format}.csv\")\n",
    "    test_df[format]['match_id'] = test_df[format]['match_id'].astype(str)\n",
    "    test_df_after_10nov[format] = pd.read_csv(f\"../data/processed/test_after10nov/{k}_{format}.csv\")\n",
    "    test_df_after_10nov[format]['match_id'] = test_df_after_10nov[format]['match_id'].astype(str)\n",
    "\n",
    "    # model[format] = MLPModel(35, 64) ######################################################################33\n",
    "    # state_dict = torch.load(f\"../model_artifacts/{format}_model.pth\", weights_only=True)\n",
    "    # model[format].load_state_dict(state_dict)\n",
    "    # model[format].eval()\n",
    "    \n",
    "    model[format] = gam_model.to(device)\n",
    "\n",
    "    model[format].eval()\n",
    "\n",
    "players_data = pd.read_csv(\"../data/raw/cricksheet/people.csv\")\n",
    "\n",
    "# {\n",
    "#         \"A Kumble\": \"0c2730df\",\n",
    "#         \"Abdul Razzaq\": \"390ff45b\", ###\n",
    "#         \"Arshad Khan\": \"0a4c6dfd\", ###\n",
    "#         \"D Mongia\": \"99663fa5\",\n",
    "#         \"Harbhajan Singh\": \"8b5b6769\",\n",
    "#         \"Iftikhar Anjum\": \"6adf9347\", ###\n",
    "#         \"Inzamam-ul-Haq\": \"b9a3d8c6\", ###\n",
    "#         \"Kamran Akmal\": \"ff077124\", ###\n",
    "#         \"L Balaji\": \"b2b50355\",\n",
    "#         \"M Kaif\": \"d84378a4\",\n",
    "#         \"MS Dhoni\": \"4a8a2e3b\",\n",
    "#         \"Mohammad Hafeez\": \"9ab63e7b\",\n",
    "#         \"Yousuf Youhana\": \"e237b28c\", ###\n",
    "#         \"Naved-ul-Hasan\": \"33f28243\", ###\n",
    "#         \"R Dravid\": \"0184dc35\",\n",
    "#         \"SR Tendulkar\": \"d2c2b2d5\",\n",
    "#         \"Salman Butt\": \"4d6d6280\", ###\n",
    "#         \"Shahid Afridi\": \"0dc00542\", ###\n",
    "#         \"Shoaib Malik\": \"64c34cd0\", ###\n",
    "#         \"V Sehwag\": \"8ba8195d\",\n",
    "#         \"Younis Khan\": \"33cb3411\", ###\n",
    "#         \"Yuvraj Singh\": \"1c914163\",\n",
    "#         \"Z Khan\": \"91a4a398\"}\n",
    "\n",
    "ids = [\n",
    "    # Pakistan Players\n",
    "    \"390ff45b\", \"6adf9347\", \"b9a3d8c6\", \"ff077124\", \"64c34cd0\",\n",
    "    \"e237b28c\", \"33f28243\", \"4d6d6280\", \"0dc00542\", \"0a4c6dfd\",\n",
    "    \"33cb3411\",\n",
    "\n",
    "    # India Players\n",
    "    \"99663fa5\", \"8b5b6769\", \"b2b50355\", \"d84378a4\", \"4a8a2e3b\", \n",
    "    \"0184dc35\", \"0c2730df\", \"d2c2b2d5\", \"8ba8195d\", \"1c914163\",\n",
    "    \"91a4a398\",\n",
    "]\n",
    "date = \"2005-04-15\"\n",
    "format = \"OD\"\n",
    "\n",
    "# print(test_df[format])\n",
    "def forward(date, format, players_id_list, match_id=None):\n",
    "    date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    target_date = datetime.strptime(\"2005-04-15\", \"%Y-%m-%d\")\n",
    "    if date <= target_date:\n",
    "        df = test_df[format]\n",
    "        filtered_rows = df[df['match_id'] == match_id]\n",
    "    \n",
    "    else:\n",
    "        df = test_df_after_10nov[format]\n",
    "        filtered_rows = df[df['Player'].isin(players_id_list)]\n",
    "\n",
    "    debut_player_points = 10\n",
    "    debut_explaination = \"This player is making his debut in this match, so he is given a default score of 10.\"\n",
    "\n",
    "    non_debut_ids = list(filtered_rows['player_id'])\n",
    "    debut_ids = list(set(players_id_list) - set(non_debut_ids))\n",
    "    # print(filtered_rows.columns)\n",
    "    test_data = process(filtered_rows, 15, False)\n",
    "    columns = test_data.columns\n",
    "\n",
    "    y_test = filtered_rows[\"fantasy_points\"]\n",
    "    X_test = test_data \n",
    "    X_test, y_test = preprocessor.transform(X_test, y_test)\n",
    "    X_test = torch.tensor(X_test).to(device)\n",
    "    # test_data = torch.tensor(test_data).float().to(device)\n",
    "\n",
    "    # print(test_data.shape)\n",
    "    # print(model[format])\n",
    "    # Run the model with additive terms\n",
    "    with torch.no_grad():  # No gradients needed during inference\n",
    "        effects = model[format].run_with_additive_terms(X_test)\n",
    "    # print(effects)\n",
    "    additive_terms = model[format].get_additive_terms()  # List of 594 feature names (main features and tuples)\n",
    "\n",
    "    players_data2 = pd.read_csv(f\"../data/raw/cricksheet/people.csv\")\n",
    "\n",
    "    # Step 1: Identify main features and store their original indices\n",
    "    main_feature_mapping = [\n",
    "        (i, term) for i, term in enumerate(additive_terms) if not isinstance(term, tuple)\n",
    "    ]\n",
    "    original_main_feature_indices = [i for i, _ in main_feature_mapping]\n",
    "\n",
    "    # Step 2: Filter tensor to keep only main features\n",
    "    main_features_tensor = effects[:, original_main_feature_indices]  # Shape: (22, number_of_main_features)\n",
    "    print(f\"Shape of tensor with main features: {main_features_tensor.shape}\")\n",
    "\n",
    "    # Step 3: Extract top \"k\" main features for each row\n",
    "    k = 5  # Number of top features to extract\n",
    "    top_k_values, top_k_indices = torch.topk(main_features_tensor, k, dim=1)\n",
    "\n",
    "    # Step 4: Map back to original feature indices and names\n",
    "    players_data = []\n",
    "    for i, row in enumerate(main_features_tensor):\n",
    "        players_data.append({})\n",
    "        for idx in top_k_indices[i]:\n",
    "            _, feature = main_feature_mapping[idx]\n",
    "            feature_name = columns[feature]\n",
    "            players_data[i][feature_name] = main_features_tensor[i][idx].item()\n",
    "    \n",
    "    # model[format].eval()\n",
    "    # with torch.no_grad():\n",
    "    #     prediction = model[format](X_test)\n",
    "    # output = prediction\n",
    "    # print(\"Prediction = \", prediction)\n",
    "    \n",
    "    # output, non_debut_ids = zip(*sorted(zip(output, non_debut_ids), key=lambda x: x[0], reverse=True))\n",
    "    # output = list(output)\n",
    "    non_debut_ids = list(non_debut_ids)\n",
    "    non_debut_names = players_data2.loc[players_data2['identifier'].isin(players_id_list), 'name'].values\n",
    "    response = generate_explanations(players_data, non_debut_names)\n",
    "    explainations = response.text\n",
    "    separator = \"\\n---\\n\"\n",
    "    explaination_list = explainations.split(separator)\n",
    "    for text in explaination_list:\n",
    "        print(text)\n",
    "    # for explanation in explaination_list: print(explanation)\n",
    "    # explaination_list = explain_outputs(model[format], test_data, columns, non_debut_names)\n",
    "    # backup_explaination = backup_outputs(model[format], test_data, columns, non_debut_names)\n",
    "\n",
    "    output = output + [debut_player_points] * len(debut_ids)\n",
    "    explaination_list += [debut_explaination] * len(debut_ids)\n",
    "\n",
    "    \n",
    "        \n",
    "    return output, explaination_list\n",
    "\n",
    "forward(date, format, ids, match_id=\"1451893\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34,\n",
       " 33,\n",
       " (33, 34),\n",
       " 32,\n",
       " (32, 34),\n",
       " (32, 33),\n",
       " 31,\n",
       " (31, 34),\n",
       " (31, 33),\n",
       " (31, 32),\n",
       " 30,\n",
       " (30, 34),\n",
       " (30, 33),\n",
       " (30, 32),\n",
       " (30, 31),\n",
       " 29,\n",
       " (29, 34),\n",
       " (29, 33),\n",
       " (29, 32),\n",
       " (29, 31),\n",
       " 28,\n",
       " (28, 34),\n",
       " (28, 33),\n",
       " (28, 32),\n",
       " (28, 31),\n",
       " (28, 30),\n",
       " (28, 29),\n",
       " 27,\n",
       " (27, 34),\n",
       " (27, 33),\n",
       " (27, 32),\n",
       " (27, 31),\n",
       " (27, 30),\n",
       " (27, 29),\n",
       " (27, 28),\n",
       " 26,\n",
       " (26, 33),\n",
       " (26, 32),\n",
       " (26, 31),\n",
       " (26, 30),\n",
       " (26, 29),\n",
       " (26, 28),\n",
       " (26, 27),\n",
       " 25,\n",
       " (25, 34),\n",
       " (25, 33),\n",
       " (25, 32),\n",
       " (25, 31),\n",
       " (25, 30),\n",
       " (25, 29),\n",
       " (25, 28),\n",
       " (25, 27),\n",
       " (25, 26),\n",
       " 24,\n",
       " (24, 34),\n",
       " (24, 33),\n",
       " (24, 32),\n",
       " (24, 31),\n",
       " (24, 30),\n",
       " (24, 29),\n",
       " (24, 28),\n",
       " (24, 27),\n",
       " (24, 26),\n",
       " 23,\n",
       " (23, 34),\n",
       " (23, 33),\n",
       " (23, 32),\n",
       " (23, 31),\n",
       " (23, 30),\n",
       " (23, 29),\n",
       " (23, 28),\n",
       " (23, 27),\n",
       " (23, 26),\n",
       " (23, 24),\n",
       " 22,\n",
       " (22, 33),\n",
       " (22, 32),\n",
       " (22, 31),\n",
       " (22, 30),\n",
       " (22, 29),\n",
       " (22, 26),\n",
       " (22, 25),\n",
       " (22, 24),\n",
       " (22, 23),\n",
       " 21,\n",
       " (21, 33),\n",
       " (21, 32),\n",
       " (21, 31),\n",
       " (21, 30),\n",
       " (21, 29),\n",
       " (21, 26),\n",
       " (21, 25),\n",
       " (21, 24),\n",
       " (21, 23),\n",
       " (21, 22),\n",
       " 20,\n",
       " (20, 33),\n",
       " (20, 32),\n",
       " (20, 31),\n",
       " (20, 30),\n",
       " (20, 29),\n",
       " (20, 28),\n",
       " (20, 27),\n",
       " (20, 26),\n",
       " (20, 25),\n",
       " (20, 24),\n",
       " (20, 23),\n",
       " (20, 22),\n",
       " (20, 21),\n",
       " 19,\n",
       " (19, 34),\n",
       " (19, 33),\n",
       " (19, 32),\n",
       " (19, 31),\n",
       " (19, 30),\n",
       " (19, 29),\n",
       " (19, 28),\n",
       " (19, 27),\n",
       " (19, 26),\n",
       " (19, 25),\n",
       " (19, 23),\n",
       " (19, 22),\n",
       " (19, 21),\n",
       " (19, 20),\n",
       " 18,\n",
       " (18, 34),\n",
       " (18, 33),\n",
       " (18, 32),\n",
       " (18, 31),\n",
       " (18, 30),\n",
       " (18, 29),\n",
       " (18, 28),\n",
       " (18, 27),\n",
       " (18, 26),\n",
       " (18, 25),\n",
       " (18, 24),\n",
       " (18, 23),\n",
       " (18, 22),\n",
       " (18, 21),\n",
       " (18, 20),\n",
       " (18, 19),\n",
       " 17,\n",
       " (17, 34),\n",
       " (17, 33),\n",
       " (17, 32),\n",
       " (17, 31),\n",
       " (17, 30),\n",
       " (17, 29),\n",
       " (17, 28),\n",
       " (17, 27),\n",
       " (17, 26),\n",
       " (17, 25),\n",
       " (17, 24),\n",
       " (17, 23),\n",
       " (17, 22),\n",
       " (17, 21),\n",
       " (17, 20),\n",
       " (17, 18),\n",
       " 16,\n",
       " (16, 34),\n",
       " (16, 33),\n",
       " (16, 32),\n",
       " (16, 31),\n",
       " (16, 30),\n",
       " (16, 29),\n",
       " (16, 28),\n",
       " (16, 27),\n",
       " (16, 26),\n",
       " (16, 25),\n",
       " (16, 24),\n",
       " (16, 23),\n",
       " (16, 21),\n",
       " (16, 20),\n",
       " (16, 19),\n",
       " (16, 18),\n",
       " (16, 17),\n",
       " 15,\n",
       " (15, 33),\n",
       " (15, 32),\n",
       " (15, 31),\n",
       " (15, 30),\n",
       " (15, 29),\n",
       " (15, 28),\n",
       " (15, 27),\n",
       " (15, 26),\n",
       " (15, 25),\n",
       " (15, 24),\n",
       " (15, 23),\n",
       " (15, 22),\n",
       " (15, 21),\n",
       " (15, 20),\n",
       " (15, 19),\n",
       " (15, 18),\n",
       " (15, 17),\n",
       " (15, 16),\n",
       " 14,\n",
       " (14, 34),\n",
       " (14, 33),\n",
       " (14, 32),\n",
       " (14, 31),\n",
       " (14, 30),\n",
       " (14, 29),\n",
       " (14, 28),\n",
       " (14, 27),\n",
       " (14, 26),\n",
       " (14, 25),\n",
       " (14, 24),\n",
       " (14, 23),\n",
       " (14, 22),\n",
       " (14, 21),\n",
       " (14, 20),\n",
       " (14, 19),\n",
       " (14, 18),\n",
       " (14, 17),\n",
       " (14, 16),\n",
       " (14, 15),\n",
       " 13,\n",
       " (13, 34),\n",
       " (13, 33),\n",
       " (13, 32),\n",
       " (13, 31),\n",
       " (13, 30),\n",
       " (13, 29),\n",
       " (13, 28),\n",
       " (13, 27),\n",
       " (13, 25),\n",
       " (13, 24),\n",
       " (13, 23),\n",
       " (13, 22),\n",
       " (13, 21),\n",
       " (13, 20),\n",
       " (13, 19),\n",
       " (13, 18),\n",
       " (13, 16),\n",
       " (13, 15),\n",
       " (13, 14),\n",
       " 12,\n",
       " (12, 34),\n",
       " (12, 33),\n",
       " (12, 32),\n",
       " (12, 31),\n",
       " (12, 30),\n",
       " (12, 29),\n",
       " (12, 28),\n",
       " (12, 27),\n",
       " (12, 26),\n",
       " (12, 25),\n",
       " (12, 24),\n",
       " (12, 23),\n",
       " (12, 22),\n",
       " (12, 21),\n",
       " (12, 20),\n",
       " (12, 19),\n",
       " (12, 18),\n",
       " (12, 17),\n",
       " (12, 16),\n",
       " (12, 15),\n",
       " (12, 14),\n",
       " (12, 13),\n",
       " 11,\n",
       " (11, 34),\n",
       " (11, 33),\n",
       " (11, 32),\n",
       " (11, 31),\n",
       " (11, 30),\n",
       " (11, 29),\n",
       " (11, 28),\n",
       " (11, 27),\n",
       " (11, 26),\n",
       " (11, 25),\n",
       " (11, 24),\n",
       " (11, 23),\n",
       " (11, 22),\n",
       " (11, 21),\n",
       " (11, 20),\n",
       " (11, 19),\n",
       " (11, 18),\n",
       " (11, 17),\n",
       " (11, 16),\n",
       " (11, 15),\n",
       " (11, 14),\n",
       " (11, 13),\n",
       " (11, 12),\n",
       " 10,\n",
       " (10, 34),\n",
       " (10, 33),\n",
       " (10, 32),\n",
       " (10, 31),\n",
       " (10, 30),\n",
       " (10, 29),\n",
       " (10, 28),\n",
       " (10, 27),\n",
       " (10, 26),\n",
       " (10, 25),\n",
       " (10, 24),\n",
       " (10, 23),\n",
       " (10, 22),\n",
       " (10, 21),\n",
       " (10, 20),\n",
       " (10, 19),\n",
       " (10, 18),\n",
       " (10, 17),\n",
       " (10, 16),\n",
       " (10, 15),\n",
       " (10, 14),\n",
       " (10, 13),\n",
       " (10, 12),\n",
       " (10, 11),\n",
       " 9,\n",
       " (9, 34),\n",
       " (9, 33),\n",
       " (9, 32),\n",
       " (9, 31),\n",
       " (9, 30),\n",
       " (9, 29),\n",
       " (9, 28),\n",
       " (9, 27),\n",
       " (9, 26),\n",
       " (9, 25),\n",
       " (9, 24),\n",
       " (9, 23),\n",
       " (9, 22),\n",
       " (9, 21),\n",
       " (9, 20),\n",
       " (9, 19),\n",
       " (9, 18),\n",
       " (9, 17),\n",
       " (9, 16),\n",
       " (9, 14),\n",
       " (9, 13),\n",
       " (9, 12),\n",
       " (9, 11),\n",
       " (9, 10),\n",
       " 8,\n",
       " (8, 34),\n",
       " (8, 33),\n",
       " (8, 32),\n",
       " (8, 31),\n",
       " (8, 30),\n",
       " (8, 29),\n",
       " (8, 28),\n",
       " (8, 27),\n",
       " (8, 26),\n",
       " (8, 25),\n",
       " (8, 24),\n",
       " (8, 23),\n",
       " (8, 22),\n",
       " (8, 21),\n",
       " (8, 20),\n",
       " (8, 19),\n",
       " (8, 18),\n",
       " (8, 17),\n",
       " (8, 16),\n",
       " (8, 14),\n",
       " (8, 13),\n",
       " (8, 12),\n",
       " (8, 11),\n",
       " (8, 10),\n",
       " (8, 9),\n",
       " 7,\n",
       " (7, 34),\n",
       " (7, 33),\n",
       " (7, 32),\n",
       " (7, 31),\n",
       " (7, 30),\n",
       " (7, 29),\n",
       " (7, 28),\n",
       " (7, 27),\n",
       " (7, 26),\n",
       " (7, 25),\n",
       " (7, 24),\n",
       " (7, 23),\n",
       " (7, 22),\n",
       " (7, 21),\n",
       " (7, 20),\n",
       " (7, 19),\n",
       " (7, 18),\n",
       " (7, 17),\n",
       " (7, 16),\n",
       " (7, 15),\n",
       " (7, 14),\n",
       " (7, 13),\n",
       " (7, 12),\n",
       " (7, 11),\n",
       " (7, 10),\n",
       " (7, 9),\n",
       " (7, 8),\n",
       " 6,\n",
       " (6, 34),\n",
       " (6, 33),\n",
       " (6, 32),\n",
       " (6, 31),\n",
       " (6, 30),\n",
       " (6, 28),\n",
       " (6, 27),\n",
       " (6, 24),\n",
       " (6, 22),\n",
       " (6, 21),\n",
       " (6, 20),\n",
       " (6, 19),\n",
       " (6, 18),\n",
       " (6, 17),\n",
       " (6, 16),\n",
       " (6, 15),\n",
       " (6, 14),\n",
       " (6, 13),\n",
       " (6, 12),\n",
       " (6, 11),\n",
       " (6, 10),\n",
       " (6, 9),\n",
       " (6, 8),\n",
       " (6, 7),\n",
       " 5,\n",
       " (5, 34),\n",
       " (5, 33),\n",
       " (5, 31),\n",
       " (5, 30),\n",
       " (5, 29),\n",
       " (5, 28),\n",
       " (5, 27),\n",
       " (5, 26),\n",
       " (5, 24),\n",
       " (5, 23),\n",
       " (5, 22),\n",
       " (5, 21),\n",
       " (5, 20),\n",
       " (5, 19),\n",
       " (5, 18),\n",
       " (5, 17),\n",
       " (5, 16),\n",
       " (5, 15),\n",
       " (5, 14),\n",
       " (5, 13),\n",
       " (5, 12),\n",
       " (5, 11),\n",
       " (5, 10),\n",
       " (5, 9),\n",
       " (5, 8),\n",
       " (5, 7),\n",
       " (5, 6),\n",
       " 4,\n",
       " (4, 34),\n",
       " (4, 33),\n",
       " (4, 32),\n",
       " (4, 31),\n",
       " (4, 30),\n",
       " (4, 29),\n",
       " (4, 28),\n",
       " (4, 27),\n",
       " (4, 26),\n",
       " (4, 25),\n",
       " (4, 24),\n",
       " (4, 23),\n",
       " (4, 22),\n",
       " (4, 21),\n",
       " (4, 20),\n",
       " (4, 19),\n",
       " (4, 18),\n",
       " (4, 17),\n",
       " (4, 16),\n",
       " (4, 15),\n",
       " (4, 13),\n",
       " (4, 12),\n",
       " (4, 11),\n",
       " (4, 10),\n",
       " (4, 9),\n",
       " (4, 8),\n",
       " (4, 7),\n",
       " (4, 6),\n",
       " (4, 5),\n",
       " 3,\n",
       " (3, 34),\n",
       " (3, 33),\n",
       " (3, 32),\n",
       " (3, 31),\n",
       " (3, 30),\n",
       " (3, 28),\n",
       " (3, 27),\n",
       " (3, 26),\n",
       " (3, 25),\n",
       " (3, 23),\n",
       " (3, 22),\n",
       " (3, 21),\n",
       " (3, 20),\n",
       " (3, 18),\n",
       " (3, 17),\n",
       " (3, 16),\n",
       " (3, 15),\n",
       " (3, 13),\n",
       " (3, 12),\n",
       " (3, 11),\n",
       " (3, 10),\n",
       " (3, 9),\n",
       " (3, 8),\n",
       " (3, 7),\n",
       " (3, 6),\n",
       " (3, 5),\n",
       " (3, 4),\n",
       " 2,\n",
       " (2, 34),\n",
       " (2, 33),\n",
       " (2, 32),\n",
       " (2, 31),\n",
       " (2, 30),\n",
       " (2, 29),\n",
       " (2, 27),\n",
       " (2, 26),\n",
       " (2, 25),\n",
       " (2, 24),\n",
       " (2, 23),\n",
       " (2, 22),\n",
       " (2, 21),\n",
       " (2, 20),\n",
       " (2, 19),\n",
       " (2, 18),\n",
       " (2, 17),\n",
       " (2, 16),\n",
       " (2, 14),\n",
       " (2, 13),\n",
       " (2, 12),\n",
       " (2, 11),\n",
       " (2, 10),\n",
       " (2, 9),\n",
       " (2, 8),\n",
       " (2, 7),\n",
       " (2, 6),\n",
       " (2, 5),\n",
       " (2, 4),\n",
       " (2, 3),\n",
       " 1,\n",
       " (1, 34),\n",
       " (1, 33),\n",
       " (1, 32),\n",
       " (1, 31),\n",
       " (1, 30),\n",
       " (1, 29),\n",
       " (1, 28),\n",
       " (1, 27),\n",
       " (1, 26),\n",
       " (1, 25),\n",
       " (1, 24),\n",
       " (1, 23),\n",
       " (1, 22),\n",
       " (1, 21),\n",
       " (1, 20),\n",
       " (1, 19),\n",
       " (1, 18),\n",
       " (1, 17),\n",
       " (1, 16),\n",
       " (1, 15),\n",
       " (1, 14),\n",
       " (1, 13),\n",
       " (1, 11),\n",
       " (1, 10),\n",
       " (1, 9),\n",
       " (1, 8),\n",
       " (1, 7),\n",
       " (1, 6),\n",
       " (1, 5),\n",
       " (1, 4),\n",
       " (1, 3),\n",
       " (1, 2),\n",
       " 0,\n",
       " (0, 34),\n",
       " (0, 33),\n",
       " (0, 32),\n",
       " (0, 31),\n",
       " (0, 30),\n",
       " (0, 29),\n",
       " (0, 28),\n",
       " (0, 27),\n",
       " (0, 26),\n",
       " (0, 25),\n",
       " (0, 24),\n",
       " (0, 23),\n",
       " (0, 22),\n",
       " (0, 21),\n",
       " (0, 20),\n",
       " (0, 19),\n",
       " (0, 18),\n",
       " (0, 17),\n",
       " (0, 16),\n",
       " (0, 15),\n",
       " (0, 13),\n",
       " (0, 11),\n",
       " (0, 10),\n",
       " (0, 9),\n",
       " (0, 8),\n",
       " (0, 7),\n",
       " (0, 6),\n",
       " (0, 5),\n",
       " (0, 3),\n",
       " (0, 2),\n",
       " (0, 1)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gam_model.get_additive_terms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dream11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
